{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from time import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn dataset library\n",
    "from sklearn import datasets\n",
    "\n",
    "#Load dataset\n",
    "wine_data = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "target=pd.DataFrame(data= wine_data['target'],\n",
    "                     columns= ['wine_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df, target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  wine_class                    178 non-null    int32  \n",
      "dtypes: float64(13), int32(1)\n",
      "memory usage: 18.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  wine_class  \n",
       "0                          3.92   1065.0           0  \n",
       "1                          3.40   1050.0           0  \n",
       "2                          3.17   1185.0           0  \n",
       "3                          3.45   1480.0           0  \n",
       "4                          2.93    735.0           0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(df_new['wine_class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(df, df_new['wine_class'], test_size=0.25) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 13)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainData)\n",
    "\n",
    "X_train = scaler.transform(trainData)\n",
    "X_test = scaler.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5824983 , -0.60433891,  1.19427289,  1.55833148, -0.07772989,\n",
       "        0.86731527, -0.62471252,  1.25076709,  2.20475427,  3.27683688,\n",
       "       -1.60566872, -0.8157889 , -0.26863038])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.9774436090225563\n",
      "Accuracy test: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Create KNN Classifier for 5\n",
    "knn5 = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn5.fit(X_train, trainLabels)\n",
    "\n",
    "#Predict the response for train dataset\n",
    "y_pred = knn5.predict(X_train)\n",
    "\n",
    "# Mode accuracy\n",
    "m_acc = metrics.accuracy_score(trainLabels, y_pred)\n",
    "print(\"Accuracy train:\",m_acc)\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn5.predict(X_test)\n",
    "\n",
    "# Mode accuracy\n",
    "m_acc = metrics.accuracy_score(testLabels, y_pred)\n",
    "\n",
    "print(\"Accuracy test:\",m_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.9772079772079773 0.030631749414736422\n",
      "1.0\n",
      "[[16  0  0]\n",
      " [ 0 23  0]\n",
      " [ 0  0  6]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        23\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "results1 = model_selection.cross_val_score(nb_model, X_train, \n",
    "                                            trainLabels, cv=5,\n",
    "                                            scoring='accuracy')\n",
    "\n",
    "#Print cross validation score\n",
    "print(\"Accuracy\")\n",
    "print(results1.mean(), results1.std())\n",
    "\n",
    "\n",
    "nb_model.fit(X_train, trainLabels)\n",
    "predictions = nb_model.predict(X_test)\n",
    "print(accuracy_score(testLabels, predictions))\n",
    "\n",
    "print(confusion_matrix(testLabels, predictions))\n",
    "\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's take 10% of the training data and use that for validation\n",
    "(trainData_new, valData, trainLabels_new, valLabels) = train_test_split(X_train, trainLabels,\n",
    "test_size=0.1, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=92.86%\n",
      "k=3, accuracy=100.00%\n",
      "k=5, accuracy=92.86%\n",
      "k=7, accuracy=100.00%\n",
      "k=9, accuracy=100.00%\n",
      "k=11, accuracy=92.86%\n",
      "k=13, accuracy=92.86%\n",
      "k=15, accuracy=92.86%\n",
      "k=17, accuracy=85.71%\n",
      "k=19, accuracy=92.86%\n",
      "k=21, accuracy=85.71%\n",
      "k=23, accuracy=92.86%\n",
      "k=25, accuracy=92.86%\n",
      "k=27, accuracy=92.86%\n",
      "k=29, accuracy=92.86%\n",
      "k=3 achieved highest accuracy of 100.00% on validation data\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of k for our k-Nearest Neighbor classifier along with the\n",
    "# list of accuracies for each value of k\n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    "\n",
    " \n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "for k in range(1, 30, 2):\n",
    "# train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainData_new, trainLabels_new)\n",
    " \n",
    "    # evaluate the model and update the accuracies list\n",
    "    score = model.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    " \n",
    "\n",
    "#find the value of k that has the largest accuracy\n",
    "i = int(np.argmax(accuracies))\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "    accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 21  1]\n",
      " [ 0  0  6]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        16\n",
      "           1       1.00      0.91      0.95        23\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.93      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(X_train, trainLabels)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(testLabels, predictions))\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 1, 'p': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.970 (+/-0.057) for {'n_neighbors': 1, 'p': 1}\n",
      "0.932 (+/-0.073) for {'n_neighbors': 1, 'p': 2}\n",
      "0.925 (+/-0.083) for {'n_neighbors': 1, 'p': 3}\n",
      "0.940 (+/-0.060) for {'n_neighbors': 1, 'p': 4}\n",
      "0.955 (+/-0.057) for {'n_neighbors': 2, 'p': 1}\n",
      "0.932 (+/-0.058) for {'n_neighbors': 2, 'p': 2}\n",
      "0.925 (+/-0.050) for {'n_neighbors': 2, 'p': 3}\n",
      "0.932 (+/-0.031) for {'n_neighbors': 2, 'p': 4}\n",
      "0.947 (+/-0.061) for {'n_neighbors': 4, 'p': 1}\n",
      "0.940 (+/-0.076) for {'n_neighbors': 4, 'p': 2}\n",
      "0.933 (+/-0.054) for {'n_neighbors': 4, 'p': 3}\n",
      "0.940 (+/-0.037) for {'n_neighbors': 4, 'p': 4}\n",
      "0.955 (+/-0.057) for {'n_neighbors': 6, 'p': 1}\n",
      "0.955 (+/-0.032) for {'n_neighbors': 6, 'p': 2}\n",
      "0.955 (+/-0.057) for {'n_neighbors': 6, 'p': 3}\n",
      "0.955 (+/-0.057) for {'n_neighbors': 6, 'p': 4}\n",
      "0.962 (+/-0.001) for {'n_neighbors': 8, 'p': 1}\n",
      "0.955 (+/-0.032) for {'n_neighbors': 8, 'p': 2}\n",
      "0.940 (+/-0.062) for {'n_neighbors': 8, 'p': 3}\n",
      "0.932 (+/-0.059) for {'n_neighbors': 8, 'p': 4}\n",
      "0.955 (+/-0.029) for {'n_neighbors': 10, 'p': 1}\n",
      "0.954 (+/-0.058) for {'n_neighbors': 10, 'p': 2}\n",
      "0.955 (+/-0.057) for {'n_neighbors': 10, 'p': 3}\n",
      "0.947 (+/-0.078) for {'n_neighbors': 10, 'p': 4}\n",
      "0.955 (+/-0.029) for {'n_neighbors': 12, 'p': 1}\n",
      "0.970 (+/-0.057) for {'n_neighbors': 12, 'p': 2}\n",
      "0.947 (+/-0.037) for {'n_neighbors': 12, 'p': 3}\n",
      "0.940 (+/-0.062) for {'n_neighbors': 12, 'p': 4}\n",
      "0.962 (+/-0.001) for {'n_neighbors': 14, 'p': 1}\n",
      "0.940 (+/-0.037) for {'n_neighbors': 14, 'p': 2}\n",
      "0.955 (+/-0.032) for {'n_neighbors': 14, 'p': 3}\n",
      "0.932 (+/-0.075) for {'n_neighbors': 14, 'p': 4}\n",
      "0.947 (+/-0.037) for {'n_neighbors': 16, 'p': 1}\n",
      "0.940 (+/-0.038) for {'n_neighbors': 16, 'p': 2}\n",
      "0.947 (+/-0.037) for {'n_neighbors': 16, 'p': 3}\n",
      "0.940 (+/-0.060) for {'n_neighbors': 16, 'p': 4}\n",
      "0.940 (+/-0.038) for {'n_neighbors': 20, 'p': 1}\n",
      "0.947 (+/-0.078) for {'n_neighbors': 20, 'p': 2}\n",
      "0.932 (+/-0.075) for {'n_neighbors': 20, 'p': 3}\n",
      "0.940 (+/-0.060) for {'n_neighbors': 20, 'p': 4}\n",
      "0.947 (+/-0.061) for {'n_neighbors': 22, 'p': 1}\n",
      "0.947 (+/-0.061) for {'n_neighbors': 22, 'p': 2}\n",
      "0.932 (+/-0.059) for {'n_neighbors': 22, 'p': 3}\n",
      "0.947 (+/-0.037) for {'n_neighbors': 22, 'p': 4}\n",
      "0.954 (+/-0.058) for {'n_neighbors': 25, 'p': 1}\n",
      "0.947 (+/-0.037) for {'n_neighbors': 25, 'p': 2}\n",
      "0.940 (+/-0.037) for {'n_neighbors': 25, 'p': 3}\n",
      "0.940 (+/-0.038) for {'n_neighbors': 25, 'p': 4}\n",
      "0.954 (+/-0.058) for {'n_neighbors': 27, 'p': 1}\n",
      "0.940 (+/-0.038) for {'n_neighbors': 27, 'p': 2}\n",
      "0.940 (+/-0.037) for {'n_neighbors': 27, 'p': 3}\n",
      "0.940 (+/-0.062) for {'n_neighbors': 27, 'p': 4}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "knn = KNeighborsClassifier() \n",
    "tuned_parameters = [{'n_neighbors': [1,2,4,6,8,10,12,14,16,20,22,25,27],'p': [1, 2, 3, 4]}]\n",
    "\n",
    "clf = GridSearchCV(knn, tuned_parameters, cv=5)\n",
    "\n",
    "clf.fit(X_train, trainLabels)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model accuracy on test\n",
    "m_acc = metrics.accuracy_score(testLabels, y_pred)\n",
    "\n",
    "print(\"Accuracy:\",m_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  0  6]]\n",
      "EVALUATION ON TESTING DATA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.95      0.99      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "print(confusion_matrix(testLabels, y_pred))\n",
    " \n",
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
